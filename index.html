<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="VideoLoRA: A Simple Baseline for Personalized Text-to-Video Generation">
  <meta name="keywords" content="Text-to-Video, Personalized Text-to-Video generation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>VideoLoRA</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script> -->
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/WechatIMG427.jpg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>


</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop" >
      <div class="columns is-centered">
        <div class="column has-text-centered" style="height: 394px; padding-top: 30px !important;"> 
          <h1 class="title is-1 publication-title" style="width: 1250px; height: 120px; display: flex; justify-content: center;"><strong style="height: 140;"> VideoLoRA: A Simple Baseline for Personalized Text-to-Video Generation</strong></h1>
          <div class="is-size-5 publication-authors" style="height: 50px;">
            <span class="author-block">
              <a href="https://github.com/VideoLoRA-PT2V/PT2V-Bench">Chenhao Sun</a><sup>1,2</sup>,  
            </span>
            <span class="author-block">
              <a href="https://github.com/VideoLoRA-PT2V/PT2V-Bench"> Jian Ji</a><sup>1</sup>,  
            </span>
            <span class="author-block">
              <a href="https://github.com/VideoLoRA-PT2V/PT2V-Bench"> Qiang Li</a><sup>2</sup>,  
            </span>
            <span class="author-block">
              <a href="https://github.com/VideoLoRA-PT2V/PT2V-Bench"> Chen Qian</a><sup>2</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors" style="height: 40px !important;">
            <span class="author-block"><sup>1</sup>Xidian University  </span>  
            <span class="author-block"><sup>2</sup>Sensetime</span>
          </div>

          <div class="column has-text-centered" style="padding-top: 20px !important;">
            <div class="publication-links">
              <!-- Paper Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark" style="margin-top: 10px !important; height: 46.35px !important;;">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/VideoLoRA-PT2V/PT2V-Bench"
                   class="external-link button is-normal is-rounded is-dark" style="margin-top: 10px !important; height: 46.35px !important;;">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Dataset</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://youtu.be/HX43C8gujKA"
                   class="external-link button is-normal is-rounded is-dark" style="margin-top: 10px !important; height: 46.35px !important;;">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                  </a>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Paper video. -->
<section class="hero is-small">
  <div class="columns is-centered has-text-centered"  style="margin-top: -10px; margin-bottom: 20px;">
    <div class="column is-three-fifths">
      <p class="title is-4">VideoLoRA is a simple, effective baseline incorporates structured caption by LoRA fine-tuning to achieve personalization, which can capture subject’s unique motion that unobserved in state-of-the-art methods.</p>
      <div class="publication-video">
        <iframe width="560" height="315" src="https://www.youtube.com/embed/HX43C8gujKA?si=xm5EMkRCL_Nzurm3" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
      </div>
    </div>
  </div>
</section>
<!-- /Paper video.   -->

<!-- Abstract. -->
<section class="hero is-light" style="height: 440px !important;">
  <div class="container is-max-desktop" style="display: flex; justify-content: center;">
    <div class="columns is-centered has-text-centered" style="margin-top: 10px; margin-bottom: 0px;">
      <div class="column is-four-fifths" style="width: 1024px !important; padding-left: 0px !important; padding-right: 0px !important;" ">
        <h2 class="title is-3" style="height: 20px; !important;">Abstract</h2>
        <div class="content has-text-justified" style="font-size: 1.25em;">
          <p>
            Personalized text-to-video (PT2V) generation aims to adapt a pretrained text-to-video model to generate customized videos of a unique subject or motion, via finetuning. To handle this problem, most of existing methods either employ image-based customization, or upgrade it with motion customization, or leverage large-scale video datasets to train subject-to-video generation. Though effective at large, these methods are not easily comparable to each other due to different backbones and implementations. In this work, we systematically analyze PT2V under the setting of LoRA finetuning by comparing three basic approaches among which we suggest a simple baseline VideoLoRA. In particular, we introduce a structured caption strategy to optimize video text descriptions and enable both subject and motion personalization. In addition, to facilitate evaluation, we curate a video dataset called PT2V-Bench, which includes videos and structured captions for 20 distinct subjects. Our results demonstrate that all three basic approaches can generate high-quality personalized videos, while VideoLoRA even captures the unique motion of the subject which is not observed in state-of-the-art methods.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- /Abstract. -->

<!-- Method. -->
<section class="hero is-small" style="margin-top:-30px; margin-bottom:-30px;">
  <div class="container is-max-desktop" style="display: flex; justify-content: center;">
    <div class="hero-body" style="width: 1430px; height: 798px;">
      <div class="columns is-centered has-text-centered">
        <div class="column" style="width: 1430px; padding-top: 60px !important; padding-bottom: 0px !important;">
          <h2 class="title is-3 is-centered">PT2V-Bench (Structured Caption)</h2>
          <div class="publication-img" style="display: flex; justify-content: center; gap: 0; max-width: 1430px; overflow: hidden;">
            <img src="./static/images/video_collection.gif" style="height: 480px; width: auto; margin: 0; padding: 0;" />
            <img src="./static/images/Multi.gif" style="height: 480px; width: auto; margin: 0; padding: 0;" />
            <img src="./static/images/per_caption.gif" style="height: 480px; width: auto; margin: 0; padding: 0;" />
            <img src="./static/images/PT2V-Bench.gif" style="height: 480px; width: auto; margin: 0; padding: 0;" />
          </div>
        </div>
      </div>
      <p style="text-align: justify;">
        <strong>PT2V-Bench Pipeline.</strong> We collected video materials of 20 topics through short video platforms and our own videos. For each video, we obtained preliminary description words through multiple rounds of dialogue with CogVLM2-Video, and then manually modified and polished them to form structured caption, and finally formed video-text pairs. We also provided corresponding test captions for each subject. Finally, our PT2V-Bench was formed.
      </p>
    </div>
  </div>
</section>
<!-- Method. -->


<section>
  <div class="container" style="width: 1380px; margin: 0 auto; margin-top: -100px; margin-bottom: -50px; display: flex; flex-direction: column; gap: 40px;">
    
    <!-- 第一行，包含标题 -->
    <div class="row" style="display: flex; gap: 40px;">
      <!-- 左侧列：Reference Videos (4个重叠视频) -->
      <div style="width: 420px; position: relative;">
        <h2 class="title is-4 has-text-centered">Reference Videos</h2>
        <div class="reference-videos">
          <video autoplay muted loop playsinline style="position: absolute; top: 60px; left: 20px; width: 55%;">
            <source src="./static/videos/nailong/2.mp4" type="video/mp4">
          </video>
          <video autoplay muted loop playsinline style="position: absolute; top: 186px; left: 170px; width: 55%;">
            <source src="./static/videos/nailong/3.mp4" type="video/mp4">
          </video>
          <video autoplay muted loop playsinline style="position: absolute; top: 160px; left: 0px; width: 55%;">
            <source src="./static/videos/nailong/4.mp4" type="video/mp4">
          </video>
          <video autoplay muted loop playsinline style="position: absolute; top: 80px; left: 200px; width: 55%;">
            <source src="./static/videos/nailong/5.mp4" type="video/mp4">
          </video>
        </div>
      </div>

      <!-- 右侧列：每次显示两个视频并滑动切换 -->
      <div style="width: 920px; position: relative;">
        <h2 class="title is-4 has-text-centered">VideoLoRA Structured Caption Customization</h2>
        <div class="video-carousel" style="overflow: hidden; position: relative; width: 100%; display: flex;">
          <!-- 包含视频的滑动容器 -->
          <div id="carouselContainer" class="video-scroll" style="display: flex; transition: transform 1s ease;">
            <video autoplay muted loop playsinline style="width: 430px;">
              <source src="./static/videos/nailong/gen/nailong.mp4" type="video/mp4">
            </video>
            <video autoplay muted loop playsinline style="width: 430px;">
              <source src="./static/videos/nailong/gen/ood_video.mp4" type="video/mp4">
            </video>
            <video autoplay muted loop playsinline style="width: 430px;">
              <source src="./static/videos/nailong/gen/nailong_video_stru.mp4" type="video/mp4">
            </video>
            <video autoplay muted loop playsinline style="width: 430px;">
              <source src="./static/videos/nailong/gen/Minus 2024-10-10 19.12.28.mp4" type="video/mp4">
            </video>
          </div>
        </div>
        <!-- 左右切换按钮 -->
        <button onclick="prevVideos()" style="position: absolute; top: 50%; left: -50px; transform: translateY(-50%);">❮</button>
        <button onclick="nextVideos()" style="position: absolute; top: 50%; right: -50px; transform: translateY(-50%);">❯</button>
      </div>
    </div>
  </div>
</section>

<style>
.video-scroll {
  display: flex;
  transition: transform 1s ease; /* 平滑滑动效果 */
}
</style>

<script>
  // 视频源路径数组
  const videoSources = [
    './static/videos/nailong/gen/nailong.mp4',
    './static/videos/nailong/gen/ood_video.mp4',
    './static/videos/nailong/gen/nailong_video_stru.mp4',
    './static/videos/nailong/gen/Minus 2024-10-10 19.12.28.mp4'
  ];

  let currentIndex = 0; // 当前展示的起始索引
  const carouselContainer = document.getElementById('carouselContainer');

  // 更新视频显示的函数，设置平移偏移量
  function updateVideos() {
    carouselContainer.style.transform = `translateX(-${currentIndex * 430}px)`;
  }

  // 下一页
  function nextVideos() {
    currentIndex = (currentIndex + 2) % videoSources.length;
    updateVideos();
  }

  // 上一页
  function prevVideos() {
    currentIndex = (currentIndex - 2 + videoSources.length) % videoSources.length;
    updateVideos();
  }

  // 自动切换每10秒
  setInterval(nextVideos, 10000);

</script>


<!-- Results -->
<!-- <section>
  <div class="container is-max-desktop" style="margin-top:-100px; margin-bottom:-50px;">
    <div class="hero-body">
      <div class="columns is-centered has-text-centered">
        <div class="column">
          <h2 class="title is-3 is-centered">VideoLoRA & Structured Caption Customization</h2>
        </div>
      </div>
      <video id="result-comparison" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/result-comparison-both1.mp4" type="video/mp4">
      </video>
      <video id="result-comparison" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/result-comparison-both2.mp4" type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        MotionBooth compared with baseline models for motion-aware customized video generation.
      </h2>
    </div>
  </div>
</section>

<section>
  <div class="container is-max-desktop" style="margin-top:-50px; margin-bottom:-50px;">
    <div class="hero-body">
      <video id="result-comparison" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/result-comparison-camera1.mp4" type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        MotionBooth compared with baseline models for camera control.
      </h2>
    </div>
  </div>
</section>

<section>
  <div class="container is-max-desktop" style="margin-top:-50px; margin-bottom:-50px;">
    <div class="hero-body">
      <video id="result-comparison" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/more-results1.mp4" type="video/mp4">
      </video>
      <video id="result-comparison" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/more-results2.mp4" type="video/mp4">
      </video>
      <video id="result-comparison" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/more-results3.mp4" type="video/mp4">
      </video>
      <video id="result-comparison" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/more-results4.mp4" type="video/mp4">
      </video>
      <video id="result-comparison" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/more-results5.mp4" type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        More results of MotionBooth.
      </h2>
    </div>
  </div>
</section> -->
<!-- /Results -->

<!-- BibTeX -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>article{wu2024motionbooth,
      title={MotionBooth: Motion-Aware Customized Text-to-Video Generation},
      author={Jianzong Wu and Xiangtai Li and Yanhong Zeng and Jiangning Zhang and Qianyu Zhou and Yining Li and Yunhai Tong and Kai Chen},
      journal={NeurIPS},
      year={2024},
    }</code></pre>
  </div>
</section>
<!-- /BibTeX -->

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Website source code based on the <a href="https://nerfies.github.io/"> Nerfies</a> project page. Thanks for their excellent work.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
